{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lithops import Storage,storage\n",
    "from lithops.multiprocessing import Pool\n",
    "from itertools import product\n",
    "import lithops\n",
    "import json\n",
    "import io\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                         Id        Date  Retweet             location  \\\n0       1275180321332289536  2020-06-22     True  Northern California   \n1       1222225270972780545  2020-01-28     True               Panama   \n2       1231665892821524481  2020-02-23    False                  NaN   \n3       1241317669619597312  2020-03-21     True                  NaN   \n4       1240298080940879872  2020-03-18     True                  NaN   \n...                     ...         ...      ...                  ...   \n104413  1296143097924124672  2020-08-19    False  41.282988-95.987779   \n104414  1381504926212296704  2021-04-12     True                Earth   \n104415  1251307219154599936  2020-04-18     True        Washington DC   \n104416  1290772296278433793  2020-08-04    False       Chattanooga TN   \n104417  1336369493975642112  2020-12-08     True        Washington DC   \n\n                                                     Text  Sentiment  \n0       Wear your mask.Help slow the spread of #COVID1...     0.0000  \n1       #Coronavirus Outbreak ⬇️Confirmed cases in Chi...    -0.4767  \n2       Rise in cases of coronavirus in Italy https://...     0.0000  \n3       If you have Coronavirus symptoms you must put ...    -0.3818  \n4       Korea just developed the KF80 mask which can b...     0.3182  \n...                                                   ...        ...  \n104413  Absolutely no one paying attention to Covid an...    -0.3804  \n104414  The proposed structure of the 2021 #HLPF Minis...     0.4215  \n104415  “It’s all part of their Hats Off to Our Heroes...     0.7712  \n104416  HAPPENING NOW: President Donald Trump gives a ...     0.2732  \n104417  #COVID19 Behavior #Policing: Rehearsal for Cra...    -0.4939  \n\n[104418 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "stg = Storage()\n",
    "data = stg.get_object('analysis.data', 'processeddata/sentimentsData.csv').decode()\n",
    "data = io.StringIO(data)\n",
    "df = pd.read_csv(data, sep=\",\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(date, df):\n",
    "    mean = df.loc[df['Date'] == date]['Sentiment'].mean()\n",
    "    return(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-0.03796050420168067\n"
     ]
    }
   ],
   "source": [
    "print(average('2021-01-18', df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                         Id        Date  Retweet             location  \\\n",
      "0       1275180321332289536  2020-06-22     True  Northern California   \n",
      "1       1222225270972780545  2020-01-28     True               Panama   \n",
      "2       1231665892821524481  2020-02-23    False                  NaN   \n",
      "3       1241317669619597312  2020-03-21     True                  NaN   \n",
      "4       1240298080940879872  2020-03-18     True                  NaN   \n",
      "...                     ...         ...      ...                  ...   \n",
      "104413  1296143097924124672  2020-08-19    False  41.282988-95.987779   \n",
      "104414  1381504926212296704  2021-04-12     True                Earth   \n",
      "104415  1251307219154599936  2020-04-18     True        Washington DC   \n",
      "104416  1290772296278433793  2020-08-04    False       Chattanooga TN   \n",
      "104417  1336369493975642112  2020-12-08     True        Washington DC   \n",
      "\n",
      "                                                     Text  Sentiment  \n",
      "0       Wear your mask.Help slow the spread of #COVID1...     0.0000  \n",
      "1       #Coronavirus Outbreak ⬇️Confirmed cases in Chi...    -0.4767  \n",
      "2       Rise in cases of coronavirus in Italy https://...     0.0000  \n",
      "3       If you have Coronavirus symptoms you must put ...    -0.3818  \n",
      "4       Korea just developed the KF80 mask which can b...     0.3182  \n",
      "...                                                   ...        ...  \n",
      "104413  Absolutely no one paying attention to Covid an...    -0.3804  \n",
      "104414  The proposed structure of the 2021 #HLPF Minis...     0.4215  \n",
      "104415  “It’s all part of their Hats Off to Our Heroes...     0.7712  \n",
      "104416  HAPPENING NOW: President Donald Trump gives a ...     0.2732  \n",
      "104417  #COVID19 Behavior #Policing: Rehearsal for Cra...    -0.4939  \n",
      "\n",
      "[104418 rows x 6 columns]\n",
      "                        Id        Date  Retweet               location  \\\n",
      "94723  1393775345594028036  2021-05-16     True        GayaBihar India   \n",
      "68533  1393774480481144833  2021-05-16     True                    NaN   \n",
      "43021  1393769827240534023  2021-05-16     True                  Tokyo   \n",
      "96001  1393769374058643456  2021-05-16     True                    NaN   \n",
      "56261  1393764474935336960  2021-05-16     True                  India   \n",
      "...                    ...         ...      ...                    ...   \n",
      "6695   1221247702702481413  2020-01-26     True  Largo Pinellas Co. FL   \n",
      "55952  1220873289758699521  2020-01-25    False                    NaN   \n",
      "32596  1220682969016193024  2020-01-24     True                    NaN   \n",
      "56941  1220630296954994688  2020-01-24     True          Lower Alabama   \n",
      "44382  1220538647193145344  2020-01-24     True             California   \n",
      "\n",
      "                                                    Text  Sentiment  \n",
      "94723  Plasma therapy most likely to be dropped from ...     0.0000  \n",
      "68533  What about advance payment? Did this charlatan...     0.0000  \n",
      "43021  Tokyo Olympics and internal discontent over Co...     0.0000  \n",
      "96001  #BareillyNeed #Blood Type :  O-positiveAt : Sa...     0.0772  \n",
      "56261  The first #OxygenExpress to Kerala is on its w...     0.4019  \n",
      "...                                                  ...        ...  \n",
      "6695   Health officials announced Friday that a secon...    -0.5423  \n",
      "55952  Dude some girl in Chicago is dead from that vi...    -0.6486  \n",
      "32596  rt to save life #coronavirus https://t.co/xQ8z...     0.4939  \n",
      "56941  With the Wuhan coronavirus spreading across th...    -0.6597  \n",
      "44382  Breaking : WHO scientists discover that the Co...    -0.8360  \n",
      "\n",
      "[104418 rows x 6 columns]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'daySent = df[[\\'Sentiment\\']].groupby(df[\\'Date\\'],axis=0).mean()[\"Sentiment\"]\\ndates = df[\\'Date\\'].unique()\\n#rint(daySent)\\n#daySent.plot(x=\"Name\", y=\"Sentiment\", kind=\"scatter\")\\nd = pd.DataFrame({\\'x\\':dates, \\'y\\':daySent})\\nd.plot(\\'Date\\', \\'Sentiment\\', kind=\\'scatter\\')'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "#print(df.describe())\n",
    "print(df)\n",
    "print(df.sort_values(by=['Id','Date'], ascending=[False, False]))\n",
    "'''daySent = df[['Sentiment']].groupby(df['Date'],axis=0).mean()[\"Sentiment\"]\n",
    "dates = df['Date'].unique()\n",
    "#rint(daySent)\n",
    "#daySent.plot(x=\"Name\", y=\"Sentiment\", kind=\"scatter\")\n",
    "d = pd.DataFrame({'x':dates, 'y':daySent})\n",
    "d.plot('Date', 'Sentiment', kind='scatter')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Location'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-36f417e5c023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat_totals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Location\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#cat_totals.plot(kind=\"barh\", fontsize=4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_totals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   6513\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6515\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   6516\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6517\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Location'"
     ]
    }
   ],
   "source": [
    "cat_totals = df.groupby(\"Location\")[\"Sentiment\"].mean().sort_values()\n",
    "#cat_totals.plot(kind=\"barh\", fontsize=4)\n",
    "print(cat_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '--ip=127.0.0.1'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fb66c67361f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mfileN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id_str'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id_str\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id_str\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '--ip=127.0.0.1'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "import re\n",
    "import csv \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import pandas as pd \n",
    "\n",
    "fileN = sys.argv[1]\n",
    "\n",
    "data = pd.read_csv(fileN, sep='\\t',encoding = 'utf8',lineterminator='\\n', usecols = [2,3], names=['id_str','text'] ,low_memory=False, dtype=str)\n",
    "\n",
    "data[\"id_str\"]=data[\"id_str\"].astype(str)\n",
    "data[\"text\"]=data[\"text\"].astype(str)\n",
    "  \n",
    "# Preprocessing \n",
    "def remove_string_special_characters(s): \n",
    "    stripped = str(s) \n",
    "    # removes special characters with ' ' \n",
    "    #stripped = re.sub('[^a-zA-z\\s]', '', str(s)) \n",
    "    #stripped = re.sub('_', '', stripped) \n",
    "      \n",
    "    # Change any white space to one space \n",
    "    stripped = re.sub('\\s+', ' ', stripped) \n",
    "\n",
    "    # Remove urls\n",
    "    stripped = re.sub(r\"http\\S+\",'', stripped)\n",
    "      \n",
    "    # Remove start and end white spaces \n",
    "    stripped = stripped.strip() \n",
    "    if stripped != '': \n",
    "            return stripped.lower() \n",
    "\n",
    "data[\"text\"]= data[\"text\"].apply(remove_string_special_characters)\n",
    "data['text'].dropna(inplace=True)\n",
    "\n",
    "# Stopword removal  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "spanishSW = set(stopwords.words('spanish'))\n",
    "stop_words.update(spanishSW)\n",
    "for i, line in enumerate(data[\"text\"]): \n",
    "    data[\"text\"][i] = ' '.join([x for x in nltk.word_tokenize(line) if ( x not in stop_words )]) \n",
    "# Getting ngrams  \n",
    "vectorizer = CountVectorizer(ngram_range = (2,3)).fit(data[\"text\"]) \n",
    "\n",
    "bag_of_words = vectorizer.transform(data[\"text\"])\n",
    "sum_words = bag_of_words.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "with open(fileN[:-4]+\"-ngram.csv\", \"w\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import collections\n",
    "import multiprocessing as mp\n",
    "import csv\n",
    "\n",
    "d = collections.defaultdict(list)\n",
    "\n",
    "def split(l):\n",
    "    return l.split(',')\n",
    "\n",
    "pool = mp.Pool(processes=4)\n",
    "for keys in pool.map(split, csv.reader(\"D:/URV/3r/2nQ/SD/practicas/SD_BigDataChallenge/datasets/englishTweetsReduced.csv\")):\n",
    "    d[keys[0]].append(keys[1:])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<_io.TextIOWrapper name='D:/URV/3r/2nQ/SD/practicas/SD_BigDataChallenge/datasets/englishTweetsReduced.csv' mode='r' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "in_file = open(\"D:/URV/3r/2nQ/SD/practicas/SD_BigDataChallenge/datasets/englishTweetsReduced.csv\")\n",
    "print(in_file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-28 13:36:39,837 [INFO] lithops.config -- Lithops v2.3.3\n",
      "2021-05-28 13:36:39,854 [INFO] lithops.storage.backends.ibm_cos.ibm_cos -- IBM COS Storage client created - Region: eu-gb\n",
      "2021-05-28 13:36:39,856 [INFO] lithops.serverless.backends.ibm_cf.ibm_cf -- IBM CF client created - Region: us-south - Namespace: david.gaseni@estudiants.urv.cat_dev\n",
      "2021-05-28 13:36:39,858 [INFO] lithops.executors -- Serverless Executor created with ID: 921c95-23\n",
      "2021-05-28 13:36:39,862 [INFO] lithops.invokers -- ExecutorID 921c95-23 | JobID M000 - Selected Runtime: buzzerage/sd_fullpackages:latest - 256MB\n",
      "2021-05-28 13:36:39,867 [INFO] lithops.job.job -- ExecutorID 921c95-23 | JobID M000 - Uploading function and data - Total: 695.0B\n",
      "2021-05-28 13:36:40,326 [INFO] lithops.invokers -- ExecutorID 921c95-23 | JobID M000 - Starting function invocation: None() - Total: 1 activations\n",
      "2021-05-28 13:36:40,336 [INFO] lithops.invokers -- ExecutorID 921c95-23 | JobID M000 - View execution logs at C:\\Users\\alexm\\AppData\\Local\\Temp\\lithops\\logs\\921c95-23-M000.log\n",
      "2021-05-28 13:36:40,342 [INFO] lithops.wait -- ExecutorID 921c95-23 - Waiting for functions to complete\n",
      "2021-05-28 13:36:45,396 [INFO] lithops.wait -- ExecutorID 921c95-23 - Getting results from functions\n",
      "2021-05-28 13:36:45,447 [INFO] lithops.executors -- ExecutorID 921c95-23 - Cleaning temporary data\n",
      "['hello bob']\n"
     ]
    }
   ],
   "source": [
    "from lithops.multiprocessing import Pool\n",
    "\n",
    "def f(name):\n",
    "    return 'hello '+str(name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool() as pool:\n",
    "        p = pool.map_async(f, ('bob',))\n",
    "        \n",
    "    print(p.get())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "try:\n",
    "        in_file = open(\"D:/URV/3r/2nQ/SD/practicas/SD_BigDataChallenge/datasets/englishTweetsReduced.csv\")\n",
    "        text = in_file.readlines()\n",
    "        with Pool() as pool:\n",
    "            p = pool.map_async(len, text)\n",
    "            #result = p.map(len,processes=process, text.split('\\n'))\n",
    "\n",
    "        print(p.get())\n",
    "except Exception as error:\n",
    "        # If an error occurred print the message to the screen\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-28 16:55:19,851 [INFO] lithops.config -- Lithops v2.3.3\n",
      "2021-05-28 16:55:19,871 [INFO] lithops.storage.backends.ibm_cos.ibm_cos -- IBM COS Storage client created - Region: eu-gb\n",
      "2021-05-28 16:55:19,875 [INFO] lithops.serverless.backends.ibm_cf.ibm_cf -- IBM CF client created - Region: us-south - Namespace: david.gaseni@estudiants.urv.cat_dev\n",
      "2021-05-28 16:55:19,877 [INFO] lithops.executors -- Serverless Executor created with ID: 01615f-33\n",
      "2021-05-28 16:55:19,883 [INFO] lithops.invokers -- ExecutorID 01615f-33 | JobID M000 - Selected Runtime: buzzerage/sd_fullpackages:latest - 1024MB\n",
      "2021-05-28 16:55:19,911 [INFO] lithops.job.job -- ExecutorID 01615f-33 | JobID M000 - Uploading function and data - Total: 4.4MiB\n",
      "2021-05-28 16:55:23,005 [INFO] lithops.invokers -- ExecutorID 01615f-33 | JobID M000 - Starting function invocation: None() - Total: 10 activations\n",
      "2021-05-28 16:55:23,049 [INFO] lithops.invokers -- ExecutorID 01615f-33 | JobID M000 - View execution logs at C:\\Users\\alexm\\AppData\\Local\\Temp\\lithops\\logs\\01615f-33-M000.log\n",
      "2021-05-28 16:55:23,056 [INFO] lithops.wait -- ExecutorID 01615f-33 - Waiting for functions to complete\n",
      "2021-05-28 16:55:31,159 [INFO] lithops.wait -- ExecutorID 01615f-33 - Getting results from functions\n",
      "2021-05-28 16:55:31,314 [INFO] lithops.executors -- ExecutorID 01615f-33 - Cleaning temporary data\n",
      "[430000, 430000, 430000, 430000, 430000, 430000, 430000, 430000, 430000, 430000]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "try:\n",
    "        in_file = open(\"D:/URV/3r/2nQ/SD/practicas/SD_BigDataChallenge/datasets/englishTweetsReduced.csv\")\n",
    "        text = in_file.readlines()\n",
    "        with Pool() as pool:\n",
    "            p = pool.map(len, text)\n",
    "            #result = p.map(len,processes=process, text.split('\\n'))\n",
    "\n",
    "        print(p)\n",
    "except Exception as error:\n",
    "        # If an error occurred print the message to the screen\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-28 20:21:52,887 [INFO] lithops.config -- Lithops v2.3.3\n",
      "2021-05-28 20:21:52,903 [INFO] lithops.storage.backends.ibm_cos.ibm_cos -- IBM COS Storage client created - Region: eu-gb\n",
      "2021-05-28 20:21:52,904 [INFO] lithops.serverless.backends.ibm_cf.ibm_cf -- IBM CF client created - Region: us-south - Namespace: david.gaseni@estudiants.urv.cat_dev\n",
      "2021-05-28 20:21:52,906 [INFO] lithops.executors -- Serverless Executor created with ID: 7301d4-1\n",
      "2021-05-28 20:21:52,908 [INFO] lithops.invokers -- ExecutorID 7301d4-1 | JobID M000 - Selected Runtime: buzzerage/sd_fullpackages:latest - 1024MB\n",
      "2021-05-28 20:21:52,938 [INFO] lithops.job.job -- ExecutorID 7301d4-1 | JobID M000 - Uploading function and data - Total: 4.4MiB\n",
      "2021-05-28 20:21:55,709 [INFO] lithops.invokers -- ExecutorID 7301d4-1 | JobID M000 - Starting function invocation: None() - Total: 10 activations\n",
      "2021-05-28 20:21:55,720 [INFO] lithops.invokers -- ExecutorID 7301d4-1 | JobID M000 - View execution logs at C:\\Users\\alexm\\AppData\\Local\\Temp\\lithops\\logs\\7301d4-1-M000.log\n",
      "2021-05-28 20:21:55,726 [INFO] lithops.wait -- ExecutorID 7301d4-1 - Waiting for functions to complete\n",
      "2021-05-28 20:22:00,795 [INFO] lithops.wait -- ExecutorID 7301d4-1 - Getting results from functions\n",
      "2021-05-28 20:22:00,868 [INFO] lithops.executors -- ExecutorID 7301d4-1 - Cleaning temporary data\n",
      "[430000, 430000, 430000, 430000, 430000, 430000, 430000, 430000, 430000, 430000]\n"
     ]
    }
   ],
   "source": [
    "from lithops.multiprocessing import Pool\n",
    "i = 1000\n",
    "j = 0\n",
    "text = {\n",
    "    'lines' : []\n",
    "}\n",
    "str_var = []\n",
    "\n",
    "def cont(dicc):\n",
    "    count = 0\n",
    "    for d in dicc['lines']:\n",
    "        count += len(d)\n",
    "    return count\n",
    "\n",
    "\n",
    "try:\n",
    "        in_file = open(\"D:/URV/3r/2nQ/SD/practicas/SD_BigDataChallenge/datasets/englishTweetsReduced.csv\")\n",
    "        '''text1 = in_file.readlines()[j:i]\n",
    "        text2 = in_file.readlines()[j:i]\n",
    "        text3 = in_file.readlines()[j:i]\n",
    "        text4 = in_file.readlines()[j:i]\n",
    "        text5 = in_file.readlines()[j:i]\n",
    "        text6 = in_file.readlines()[j:i]\n",
    "        text7 = in_file.readlines()[j:i]\n",
    "        text8 = in_file.readlines()[j:i]\n",
    "        text9 = in_file.readlines()[j:i]'''\n",
    "        full_text = in_file.readlines()\n",
    "        with Pool() as pool:\n",
    "            for i in range(0, 100000, 10000):\n",
    "                text['lines'] = full_text[j:i]\n",
    "                str_var.append(text)\n",
    "                j = i\n",
    "            \n",
    "            p = pool.map(cont, str_var)\n",
    "            print(p)\n",
    "            #result = p.map(len,processes=process, text.split('\\n'))\n",
    "except Exception as error:\n",
    "        # If an error occurred print the message to the screen\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}